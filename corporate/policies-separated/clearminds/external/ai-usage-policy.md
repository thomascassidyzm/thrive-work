---
title: AI Usage Policy
subtitle: Guidelines for Responsible AI Implementation
policy_owner: Technology & Compliance Department
effective_date: July 2025
review_date: July 2026
version: 1.0
applies_to: All ClearMinds staff, contractors, and service providers
reference: CM-AI-001
---

# AI Usage Policy

## Purpose & Scope

This policy establishes ClearMinds's framework for the responsible, ethical, and transparent use of artificial intelligence (AI) technologies in our services. It ensures that AI is deployed in ways that enhance our wellbeing offerings whilst maintaining the highest standards of data protection, user privacy, and clinical safety.

### Our Commitment

ClearMinds is committed to using AI as a tool to empower individuals in their wellbeing journey, not to replace the human expertise and compassion that underpin our services. All AI implementations must enhance, not diminish, the quality of care and support we provide.

## 1. AI in Content Generation

### 1.1 Therapeutic Content

All therapeutic content, including hypnotherapy scripts, meditation guidance, and mindfulness exercises, is created primarily by qualified therapists and clinical professionals. AI may be used to:

- Assist in research and evidence gathering
- Suggest structural improvements to existing content
- Generate initial drafts for review by qualified professionals
- Translate content whilst maintaining therapeutic integrity

**All AI-assisted content must be reviewed, validated, and approved by qualified clinical professionals before release.**

### 1.2 Marketing & Communication

AI may be used to support marketing content creation, provided that:

- All claims remain evidence-based and compliant with ASA guidelines
- The ClearMinds tone of voice (supportive, clear, authoritative) is maintained
- UK English spelling and phrasing is used throughout
- Content is reviewed for accuracy and brand consistency

## 2. Data Protection & Privacy

### 2.1 User Data Handling

AI systems processing personal data must comply with GDPR and UK data protection legislation:

- **Data minimisation:** Only necessary data is processed by AI systems
- **Consent:** Users must be informed when AI processes their personal data
- **Anonymisation:** Personal identifiers removed wherever possible
- **Retention limits:** AI training data subject to standard retention policies
- **Right to object:** Users can opt-out of AI-driven personalisation

### 2.2 Third-Party AI Services

When using external AI services (e.g., ChatGPT, Claude, other LLMs):

- Data processing agreements must be in place
- Personal data must not be shared without explicit consent
- Usage logs maintained for audit purposes
- Regular vendor assessments conducted

## 3. AI in Service Delivery

### 3.1 Personalisation & Recommendations

AI may be used to personalise user experiences and recommend appropriate content, provided that:

- Recommendations are clinically appropriate and safe
- Users can easily understand why content was recommended
- Human oversight mechanisms are in place
- Users can opt-out of AI-driven personalisation

### 3.2 Chatbots & Automated Support

AI chatbots must:

- Clearly identify themselves as automated systems
- Know their limitations and escalate appropriately
- Never provide clinical advice or diagnoses
- Include clear pathways to human support
- Be regularly reviewed for accuracy and appropriateness

### Red Line: Clinical Decisions

AI systems must never make autonomous clinical decisions, provide diagnoses, or replace qualified human judgement in therapeutic contexts. All clinical decisions require human oversight from qualified professionals.

## 4. Transparency & Disclosure

### 4.1 User Communication

Users must be clearly informed when:

- They are interacting with an AI system rather than a human
- AI has been used in creating or personalising content
- Their data may be processed by AI systems
- AI-driven recommendations are being provided

### 4.2 Partner & Corporate Transparency

Our corporate partners have a right to know:

- Which services utilise AI technology
- How AI impacts service delivery and quality
- What safeguards are in place
- How user data is processed

## 5. Quality Assurance & Safety

### 5.1 Content Quality Control

All AI-generated or AI-assisted content undergoes:

- **Clinical review:** By qualified therapists for therapeutic content
- **Accuracy check:** Fact-checking and evidence validation
- **Brand alignment:** Tone, voice, and messaging consistency
- **Safety review:** Ensuring no harmful or triggering content
- **Legal compliance:** ASA, GDPR, and advertising standards

### 5.2 Monitoring & Auditing

Regular monitoring includes:

- Quarterly reviews of AI system performance
- User feedback analysis on AI-driven features
- Bias detection and mitigation assessments
- Security audits of AI systems
- Compliance checks against evolving regulations

## 6. Ethical AI Principles

### 6.1 Core Principles

ClearMinds commits to:

- **Human-centric:** AI serves people, not profits
- **Transparent:** Clear about AI use and limitations
- **Fair:** Actively identifying and mitigating bias
- **Accountable:** Clear responsibility for AI decisions
- **Safe:** User wellbeing is paramount
- **Sustainable:** Considering environmental impact

### 6.2 Bias & Discrimination

We actively work to prevent AI bias by:

- Using diverse training data
- Regular bias audits of AI outputs
- Inclusive design processes
- Diverse team input on AI development
- User feedback mechanisms

## 7. Staff Training & Competence

### 7.1 Training Requirements

All staff using AI tools must complete:

- AI policy and ethics training
- Data protection training specific to AI
- Tool-specific training for AI platforms used
- Annual refresher training

### 7.2 Competence Standards

Staff must demonstrate:

- Understanding of AI limitations
- Ability to critically evaluate AI outputs
- Knowledge of when human intervention is required
- Awareness of ethical considerations

## 8. Governance & Oversight

### 8.1 Responsible Parties

- **AI Policy Owner:** Chief Technology Officer
- **Clinical Oversight:** Clinical Governance Lead
- **Data Protection:** Data Protection Officer
- **Ethics Review:** Ethics Committee

### 8.2 Policy Review

This policy is reviewed annually or sooner if:

- New AI technologies are adopted
- Regulatory changes occur
- Incidents or concerns arise
- Significant user feedback received

## 9. Incident Reporting

### 9.1 Reportable Issues

Staff must report:

- AI-generated content that is inappropriate, harmful, or inaccurate
- Potential bias or discrimination in AI outputs
- Data protection breaches involving AI systems
- User complaints about AI functionality
- Safety concerns related to AI recommendations

### 9.2 Response Procedures

All incidents are:

- Logged in the incident management system
- Investigated within 48 hours
- Reviewed by appropriate governance bodies
- Addressed with corrective actions
- Used to improve AI policies and practices

## 10. Compliance & Enforcement

### 10.1 Policy Compliance

Non-compliance with this policy may result in:

- Retraining requirements
- Restriction of AI tool access
- Disciplinary action
- In serious cases, termination of employment

### 10.2 External Compliance

This policy ensures compliance with:

- UK GDPR and Data Protection Act 2018
- Advertising Standards Authority (ASA) guidelines
- NHS Digital guidance on AI in healthcare
- Equality Act 2010
- Emerging AI-specific legislation

### Questions or Concerns?

If you have questions about this policy or concerns about AI use at ClearMinds, please contact:

- **Email:** ai-governance@clearminds.com
- **Data Protection Officer:** dpo@clearminds.com

---

**Document Control**

Policy Reference: CM-AI-001 | Version: 1.0 | Approved by: Board of Directors | Next Review: July 2026

Â© 2024 ClearMinds. All rights reserved.
